{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pOUKIp9VC0gQ"
   },
   "source": [
    "# CT5120 Assignment 2\n",
    "\n",
    "This task is focused on sentiment classification and span extraction from tweets. Please complete this task and upload your answers to Canvas as an iPython Notebook or a PDF. This assignment is due by 23:59 on December 10th 2023. Late submissions will be penalised by 1% for each day after this date. This is an individual assignment and your work must be your own.\n",
    "\n",
    "You may use libraries such as SciKit-Learn to complete this assignment, however you should justify the choice of functions from these libraries.\n",
    "\n",
    "**Summary**\n",
    "\n",
    "In this task, given a tweet (text) we have two objectives:\n",
    "\n",
    "1. Sentiment classification: Classify the tweet into one of three classes (positive, negative, neutral).\n",
    "\n",
    "2. Sentiment span extraction: Extract the sequence of words from the tweet that expresses the given sentiment.\n",
    "\n",
    "Consider the following example from the train dataset:\n",
    "\n",
    "| textID | text | selected_text | sentiment |\n",
    "| ------ | ---- | ------------- | --------- |\n",
    "| 266b8792a0 |Just broke my favorite necklace  superglue? | Just broke my favorite necklace | negative |\n",
    "| 8f3e73cf09 | \"Screw the reviews, I thought Wolverine was awesome. But not enough Dominic Monaghan for my liking.\" | I thought Wolverine was awesome. | positive |\n",
    "|... | ... | ... | ... |\n",
    "| 266b8792a0 |Just broke my favorite necklace  superglue? | Just broke my favorite necklace | negative |\n",
    "\n",
    "\n",
    "The dataset is divided into `train`, `dev` and `test` sets. The `train` set is used for the model training, while the `dev` set is used for validation and hyperparameter tuning.\n",
    "\n",
    "The test dataset has **no sentiment labels**. This dataset split will be used for **leaderboard submission** for sentiment classification modelling, described in section 2.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bS4AHgRYC0gT"
   },
   "source": [
    "# 1. Data Analysis\n",
    "    \n",
    "## Task 1a\n",
    "\n",
    "Plot a group bar plot to show the distribution of sentiment classes (positive, negative, neutral) in the train and dev dataset. As shown in the following illustration. `(10 marks)`\n",
    "    \n",
    "    \n",
    "   <img src=\"https://github.com/gauneg/gauneg.github.io/blob/main/ds1.jpg?raw=true\" alt=\"PLOT EXAMPLE\" width=\"400px\"/>\n",
    "\n",
    "\n",
    "\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "train_df = pd.read_csv(\"train_new.csv\")\n",
    "test_df = pd.read_csv(\"test_new.csv\")\n",
    "dev_df = pd.read_csv(\"dev_new.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "neutral     8608\n",
       "positive    6644\n",
       "negative    6025\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.sentiment.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "neutral     453\n",
       "positive    350\n",
       "negative    317\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_df.sentiment.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KZdmAEjvC0gT"
   },
   "source": [
    "# 2. Sentiment Classification\n",
    "\n",
    "## Task 2a\n",
    "\n",
    "Train a sequence classification model. The model should take the `text` as input and return one out of 3 sentiment classes: `negative`, `neutral` or `positive`.\n",
    "\n",
    "\n",
    "\n",
    "<img src=\"https://github.com/gauneg/gauneg.github.io/blob/main/sentiment_classification.png?raw=true\" alt=\"PLOT EXAMPLE\" width=\"500px\"/>\n",
    "\n",
    "    \n",
    "INPUT : (`text`)\n",
    "\n",
    "OUTPUT: `sentiment_class` i.e. one class from `(positive, negative, neutral)`\n",
    "\n",
    "\n",
    "* You should preprocess the data in the training and development sets and extract feature vectors using either bag-of-words or TF-IDF. `(15 marks)`\n",
    "* Using these features please train a classifier using a method such Support Vector Machines (SVM) `(10 marks)`\n",
    "\n",
    "Please provide an  implementation along with an **explanation** (no more than 5 0 words) of the method used and any libraries you used to do this.\n",
    "\n",
    "## Task 2b\n",
    "\n",
    "Use the `text` and `sentiment` of the dev set to calulate the efficiency of your model by calculating the following metrics for each class:\n",
    "    \n",
    "- Precision\n",
    "\n",
    "- Recall\n",
    "\n",
    "- F1 Score\n",
    "    \n",
    "Considering it is a multi-class classification task, you should also report the macro-average scores in your implementation of the automatic metrics.\n",
    "Please provide an implementation along with an **explanation** (no more than 50 words) of the method used. `(5 marks)`\n",
    "\n",
    "\n",
    "## Task 2c\n",
    "\n",
    "Based on the methods discussed in the lecture suggest **ONE** improvement or alternative approach that can be applied to the sentiment classification task as in Task 2a. This may be through better feature extraction, new modelling or through an alternaitve methodology.\n",
    "\n",
    "You should implement this approach and compare the results using the evaluation from Task 2b.\n",
    "\n",
    "Provide an **explanation** of your approach in no more than 100 words.\n",
    "\n",
    "`(20 marks)`\n",
    "\n",
    "## Task 2d\n",
    "Join the closed kaggle competition at this [link](https://www.kaggle.com/t/c485f589d0694836be2dcecd01a7da4a). Follow the instructions. In order to join the competion login to kaggle using your `universityofgalway` email account. Make a successful submission. Apply the system you developed in Task 2c to the test dataset and submit this result. Marks will be awarded based on the quality of the result.\n",
    "\n",
    "`(10 marks)`\n",
    "\n",
    "Format of the test set:\n",
    "\n",
    "\n",
    "| textID | text | selected_text |\n",
    "| ------ | ---- | ------------- |\n",
    "| 266b8792a0 |Just broke my favorite necklace  superglue? | Just broke my favorite necklace |\n",
    "| 8f3e73cf09 | \"Screw the reviews, I thought Wolverine was awesome. But not enough Dominic Monaghan for my liking.\" | I thought Wolverine was awesome. |\n",
    "|... | ... | ... |\n",
    "| 266b8792a0 |Just broke my favorite necklace  superglue? | Just broke my favorite necklace |\n",
    "\n",
    "Format of the submission file `(.csv format)`:\n",
    "\n",
    "\n",
    "| textID | sentiment |\n",
    "| ------ | --------- |\n",
    "| 266b8792a0 | negative |\n",
    "| 8f3e73cf09 | positive |\n",
    "|... | ... |\n",
    "| 266b8792a0 | negative |\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2 A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_df['text']\n",
    "Y_train = train_df['sentiment']\n",
    "\n",
    "\n",
    "dev_df = dev_df.dropna(subset=['text'])\n",
    "X_dev = dev_df['text']\n",
    "Y_dev = dev_df['sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)\n",
    "X_dev_tfidf = tfidf_vectorizer.transform(X_dev)\n",
    "X_test_tfidf = tfidf_vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC(kernel=&#x27;linear&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(kernel=&#x27;linear&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "SVC(kernel='linear')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = SVC(kernel=\"linear\")\n",
    "\n",
    "model.fit(X_train_tfidf, Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.62      0.72      0.66       270\n",
      "     neutral       0.74      0.63      0.68       535\n",
      "    positive       0.67      0.75      0.70       314\n",
      "\n",
      "    accuracy                           0.68      1119\n",
      "   macro avg       0.67      0.70      0.68      1119\n",
      "weighted avg       0.69      0.68      0.68      1119\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "dev_pred = model.predict(X_dev_tfidf)\n",
    "\n",
    "print(classification_report(dev_pred, Y_dev))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['sentiment'] = model.predict(X_test_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = test_df[['textID', 'sentiment']]\n",
    "out.to_csv(\"output.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iwpy2c2OC0gT"
   },
   "source": [
    "# 3. Span Extraction\n",
    "## Task 3a\n",
    "\n",
    "\n",
    "Our goal for this task is to extract the sentiment span, given the text and the given sentiment (true sentiment label) as input. The sentiment span is a subsection of the text that expresses the sentiment that classifies the text overall.\n",
    "\n",
    "INPUT : (`text`, `sentiment`)\n",
    "\n",
    "OUTPUT: `selected_text`\n",
    "\n",
    "<img src=\"https://github.com/gauneg/gauneg.github.io/blob/main/assignment_diag.png?raw=true\" alt=\"PLOT EXAMPLE\" width=\"500px\"/>\n",
    "\n",
    "\n",
    "1. Describe in no more than 200 words a system that could be used to identify the sentiment span. You should consider the methodology potentially including how features are extracted, what models could be used and what procedures should be used to train the model. `(10 marks)`\n",
    "\n",
    "2. Implement this system and apply it to the train and development splits of the dataset. `(15 marks)`\n",
    "\n",
    "## Task 3b\n",
    "\n",
    "1. Describe an automatic metric that can be used to evaluate the task of span extraction. Implement this metric and use it to evaluate the performance of the system you developed in Task 3a. `(5 marks)`"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
